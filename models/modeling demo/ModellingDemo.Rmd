---
title: "Modelling Demo Caravan Insurance"
output: html_document
---

if (!requireNamespace("here", quietly = TRUE)) install.packages("here")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("ggplot2", quietly = TRUE)) install.packages("ggplot2")
if (!requireNamespace("skimr", quietly = TRUE)) install.packages("skimr")
if (!requireNamespace("caret", quietly = TRUE)) install.packages("caret")
if (!requireNamespace("readr", quietly = TRUE)) install.packages("readr")

#from the meeting notes

marketing_cost   <- 0.89
marketing_budget <- 50000
revenue_per_client <- 600
profit_margin <- 0.05
total_market_size <- 500000
const_seed       <- 42

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
```

This is our project for Predictive Analytics 

```{r  message=FALSE}

library(tidyverse)

# Load caTools package for data partitioning
library(caTools) 

# Import our data and assing it to churndt
churndt <- read.csv('/Users/alenslaskovs/Desktop/WHU/PA/GroupWork/MSc_Predictive_Analytics_HS25_Group_Assignment/data/processed/ticdata2000_clean.csv')

# Display the structure of the dataset

head(churndt, 10)

```

Let's start with data preparation.

* Customer ID (id) does not have any effect on the target variable. Remove that feature from the dataset.

```{r  message=FALSE}

# Remove customer ID from the dataset

#churndt <- subset(churndt, select = -id)

```

***

* Display the summary of the dataset. 

```{r  message=FALSE}

# Display the summary
str(churndt)

```

* Update the data types if necessary.

```{r  message=FALSE}

# Update the data types if necessary

# Categorical factors

---


```

***

* Split the dataset into the training (70%) and test (30%) sets by using `sample.split()` function.

```{r  message=FALSE, eval=FALSE}

# Set a seed

set.seed(1234)

# Generate a vector partition for data partitioning 
partition = sample.split(churndt$CARAVAN, SplitRatio = 0.7) 

# Create training set: training
training_set = subset(churndt, partition == TRUE) 

# Create test set: test
test = subset(churndt, partition == FALSE) 

```


# Information Gain on training set

```{r}

install.packages("FSelectorRcpp")
library(FSelectorRcpp)

ig <- information_gain(CARAVAN ~ ., data = training_set)

# Sort descending and take top 15
ig <- arrange(ig, desc(importance))
print(head(ig, 20))  # peek at top 20 for context

top_k <- 15
selected_attrs <- ig$feature[seq_len(min(top_k, nrow(ig)))]
cat("Top attributes:\n"); print(selected_attrs)

# Build reduced training subset (selected predictors + target)
subset_data <- training_set[, c(selected_attrs, "CARAVAN")]

str(subset_data)
```


# --- Inputs ---------------------------------------------------------------
shortlist <- c(
  "APERSAUT","ABRAND","AWAPART",     # household product holdings
  "PPERSAUT","PBRAND","PWAPART",     # postcode prevalence of those products
  "MINKGEM","MKOOPKLA",              # affluence / purchase power
  "MHKOOP","MOPLHOOG","MBERHOOG",    # housing, education, status
  "MOSTYPE"                          # nominal -> will be excluded if non-numeric
)

# --- 1) Select existing, numeric variables --------------------------------
vars_exist <- intersect(shortlist, names(training_set))
is_num     <- vapply(training_set[vars_exist], is.numeric, logical(1))
vars_num   <- vars_exist[is_num]

if (length(vars_num) < 2L) stop("Need at least 2 numeric variables for correlation.")

df_num <- training_set[, vars_num, drop = FALSE]

# Drop zero-variance columns
is_const <- vapply(df_num, function(x) isTRUE(var(x, na.rm = TRUE) == 0), logical(1))
if (any(is_const)) {
  message("Dropping zero-variance columns: ",
          paste(names(df_num)[is_const], collapse = ", "))
  df_num <- df_num[, !is_const, drop = FALSE]
}

if (ncol(df_num) < 2L) stop("After dropping constants, fewer than 2 variables remain.")

# --- 2) Spearman correlation matrix ---------------------------------------
cor_mat <- cor(df_num, method = "spearman", use = "pairwise.complete.obs")

# Optional: take a quick look
# print(round(cor_mat, 3))

# --- 3) Build upper-tri pair list -----------------------------------------
upper_idx <- which(upper.tri(cor_mat), arr.ind = TRUE)
pairs_df <- data.frame(
  var1 = rownames(cor_mat)[upper_idx[, 1]],
  var2 = colnames(cor_mat)[upper_idx[, 2]],
  rho  = cor_mat[upper_idx],
  stringsAsFactors = FALSE
)

# --- 4) Flag highly correlated pairs (abs rho ≥ threshold) -----------------
threshold <- 0.80
pairs_df$abs_rho <- abs(pairs_df$rho)

high_pairs <- pairs_df[pairs_df$abs_rho >= threshold, , drop = FALSE]
high_pairs <- high_pairs[order(-high_pairs$abs_rho), , drop = FALSE]

cat(sprintf("\nSpearman |rho| >= %.2f pairs:\n", threshold))
if (nrow(high_pairs)) {
  print(high_pairs, row.names = FALSE)
} else {
  cat("None found.\n")
}

#So as discussed with the group we found out that the P variables are assigned with the ZIP codes so we decided to drop the var1 and keep the var2 as it will be easier to target the end-client with (marketing,etc)


# From your shortlist
shortlist <- c(
  "APERSAUT","ABRAND","AWAPART",
  "PPERSAUT","PBRAND","PWAPART",
  "MINKGEM","MKOOPKLA",
  "MHKOOP","MOPLHOOG","MBERHOOG",
  "MOSTYPE"
)

# Drop the postcode-prevalence (2nd) variables from the high-corr pairs
drop_vars <- c("PWAPART","PPERSAUT","PBRAND")
shortlist_pruned <- setdiff(shortlist, drop_vars)


***

Next, we will learn how to build some of the predictive models. Training data would be used to train and develop our predictive models. Later, we will use test data to predict customer class (1) for churn or (0) for stay. 



**Logistic Regression Model**

Now, we will build logistic regression model 



logistic_model <- glm(formula, data = train_data, family = binomial(link = "logit"))
summary(logistic_model)



# --- Packages ---------------------------------------------------------------
if (!requireNamespace("pROC", quietly = TRUE)) install.packages("pROC")
if (!requireNamespace("caret", quietly = TRUE)) install.packages("caret")
if (!requireNamespace("car", quietly = TRUE)) install.packages("car")
library(pROC)
library(caret)
library(car)

# --- Target & types ---------------------------------------------------------
# Ensure target is factor with levels 0/1 (GLM uses 0/1 coding)
training_set$CARAVAN <- as.factor(training_set$CARAVAN)
test$CARAVAN        <- as.factor(test$CARAVAN)

# MOSTYPE should be nominal (factor) if present
if ("MOSTYPE" %in% names(training_set) && !is.factor(training_set$MOSTYPE)) {
  training_set$MOSTYPE <- as.factor(training_set$MOSTYPE)
  test$MOSTYPE        <- as.factor(test$MOSTYPE)
}

# --- Build formula from pruned features ------------------------------------
feat <- intersect(shortlist_pruned, names(training_set))
form_lr <- as.formula(paste("CARAVAN ~", paste(feat, collapse = " + ")))
form_lr

logit_mod <- glm(form_lr, data = training_set, family = binomial())

summary(logit_mod)

# Multicollinearity check (optional)
vif_vals <- car::vif(logit_mod)
print(vif_vals)


# --- Logistic ROC only ------------------------------------------------------
# Probabilities for class "1"
p_lr <- predict(logit_mod, newdata = test, type = "response")

# Ensure positive class is "1"
actual <- factor(test$CARAVAN)  # levels should be c("0","1")
roc_lr <- pROC::roc(response = actual, predictor = p_lr, levels = rev(levels(actual)))
auc_lr <- pROC::auc(roc_lr)
cat(sprintf("Logistic AUC: %.3f\n", as.numeric(auc_lr)))

# Plot ROC
plot.roc(roc_lr, legacy.axes = TRUE, col = "blue", lwd = 2,
         xlab = "False Positive Rate (1 - Specificity)",
         ylab = "True Positive Rate (Sensitivity)",
         main = "ROC — Logistic Regression")
abline(a = 0, b = 1, lty = 2)

# Mark threshold = 0.50
pt_05 <- pROC::coords(roc_lr, x = 0.5, input = "threshold",
                      ret = c("sensitivity","specificity"))
points(1 - pt_05["specificity"], pt_05["sensitivity"], pch = 19)
text(1 - pt_05["specificity"], pt_05["sensitivity"], labels = "  th=0.50", pos = 4)

# Mark Youden-optimal threshold
pt_best <- pROC::coords(roc_lr, x = "best", best.method = "youden",
                        ret = c("threshold","sensitivity","specificity"))
points(1 - pt_best["specificity"], pt_best["sensitivity"], pch = 19)
text(1 - pt_best["specificity"], pt_best["sensitivity"],
     labels = sprintf("  th=%.3f", as.numeric(pt_best["threshold"])), pos = 4)

legend("bottomright",
       legend = sprintf("Logistic Reg. (AUC = %.3f)", as.numeric(auc_lr)),
       col = "blue", lwd = 2, bty = "n")



**Decision Tree**

Now, we will build one of the decision tree models known as conditional inference tree in R. The function `ctree()` is used to create conditional trees. The main components of this function are formula (specifying which is the target variable and what  features will be used in modelling) and data. The basic syntax of this function can be given as follows:

    ctree(formula, data)

`ctree()` function is located in package `partykit`. Let's load `partykit` package and start to work on the decision tree model. 

```{r  message=FALSE, eval = FALSE}

# Install party package
install.packages("partykit")

# Load package party
library(partykit)

```

* Build a decision tree by using all features. Call this model *decTree*. We will use this model for prediction.

```{r  message=FALSE, eval = FALSE}

# Build a decision tree by using ctree() function
decTree <- partykit::ctree(as.formula(paste("CARAVAN ~", paste(shortlist_pruned, collapse = " + "))), data = training_set)

prop.table(table(training_set$CARAVAN))


# Print decTree

print(decTree)


# --- 0) Packages ------------------------------------------------------------
if (!requireNamespace("partykit", quietly = TRUE)) install.packages("partykit")
library(partykit)

# --- 1) Variables (your shortlist + pruning) --------------------------------
shortlist <- c(
  "APERSAUT","ABRAND","AWAPART",
  "PPERSAUT","PBRAND","PWAPART",
  "MINKGEM","MKOOPKLA",
  "MHKOOP","MOPLHOOG","MBERHOOG",
  "MOSTYPE"
)
drop_vars <- c("PWAPART","PPERSAUT","PBRAND")
shortlist_pruned <- setdiff(shortlist, drop_vars)

# Keep only those that exist in training_set
feat <- intersect(shortlist_pruned, names(training_set))

# If MOSTYPE is present and not a factor, coerce (nominal)
if ("MOSTYPE" %in% feat && !is.factor(training_set$MOSTYPE)) {
  training_set$MOSTYPE <- as.factor(training_set$MOSTYPE)
}
if ("MOSTYPE" %in% names(test) && !is.factor(test$MOSTYPE)) {
  test$MOSTYPE <- as.factor(test$MOSTYPE)
}

# --- 2) Build & fit the tree ------------------------------------------------
form_pruned <- as.formula(paste("CARAVAN ~", paste(feat, collapse = " + ")))
decTree <- partykit::ctree(form_pruned, data = training_set)

# Class balance in training
cat("Training class balance (proportions):\n")
print(prop.table(table(training_set$CARAVAN)))

# Print model summary
cat("\nModel summary:\n")
print(decTree)

# --- 3) Tree size & depth ---------------------------------------------------
# number of terminal (leaf) nodes
n_leaves <- length(partykit::nodeids(decTree, from = "terminal"))
# number of inner (split) nodes
n_inner  <- length(partykit::nodeids(decTree, from = "inner"))

# helper to compute maximum depth (height) of the tree
tree_depth <- function(tree) {
  recurse <- function(nd) {
    kids <- partykit::kids_node(nd)
    if (length(kids) == 0L) return(1L)
    1L + max(vapply(kids, recurse, integer(1L)))
  }
  recurse(partykit::node_party(tree))
}

cat("\nTree stats:\n")
cat("Leaves:", n_leaves, " | Inner nodes:", n_inner, " | Max depth (nodes):", tree_depth(decTree), "\n")

# --- 4) Quick evaluation on test -------------------------------------------
pred <- predict(decTree, newdata = test, type = "response")
acc  <- mean(pred == test$CARAVAN)
cat(sprintf("\nTest accuracy: %.3f\n", acc))

# Optional: simple plot
# plot(decTree, type = "simple")

```


* Build another decision tree by using features HOUSE and AVG_OVERCHARGE. We will use this model just for illustration.

```{r  message=FALSE, eval = FALSE}

# Build a decision tree by using features HOUSE and AVG_OVERCHARGE
DT <- ctree(CLASS ~ ---, data = training_set)

# Print DT
print(DT)

# Plot DT
plot(DT, type='simple')

```



* Use the *decTree* model and predict the classes in the test data using `predict()` function. 

  The syntax of `predict()` function is of the form `predict(model, testdata, type = "--")`. The first argument is the model object - technically a list - produced by a modellig functions (such as the object `DecTree` produced above). The input `testdata` denotes the testing dataset to be scored. The function takes one additional argument which is `type`. Type refers to the type of predicted value returned. For `ctree()`, type argument can take one of the following values:

  - response: the predicted class for a categorical response
  - prob: class probabilities
  - node: terminal nodes

```{r  message=FALSE, eval = FALSE}

# Predicting the Test set results 
 decTree_predict = predict(decTree, newdata = test, type = "response")

```


Let's find out how many of the predictions are correct. 

 * Copy test data to *results*

```{r message=FALSE, eval = FALSE}
 # Copy test data to results
results <- test
```

* Find the correct predictions.

```{r  message=FALSE, eval = FALSE}

#  Generate a column named PredictionTree in dataframe results and add predictions obtained by decision tree to that column
results$PredictionTree <- predict(decTree, newdata = results, type = "response" )

# Find the correct predictions
correct_Tree <- which(results$PredictionTree == results$CLASS)

# Return the total number of correct predictions
length(correct_Tree)

```




**Linear Discriminant Analysis**

Linear Discriminant analysis (LDA) is a linear classification method. This method finds the linear combination of the attributes that separates the classes of target variable. To build an LDA model, we will use `lda()` function from `MASS` package. The basic syntax of this function can be given as follows:

      lda(formula, data)
      
Let's load `MASS` package and build an LDA model by using LEFTOVER, HOUSE, AVG_OVERCHARGE and AVG_CALL features. Call this model *LDAmodel*. 

```{r  message=FALSE, eval = FALSE}

# Load MASS package
library(MASS)

# Build an LDA model by using lda() function
LDAmodel <- lda(CLASS ~ ---, data = training)

# Print model
LDAmodel

```

* Predict the classes in the test data using `predict()` function. The syntax is:

              predict(modelname, test data)

```{r  message=FALSE, eval = FALSE}

# Predict the Test set results 
 LDA_predict = predict(LDAmodel, newdata = test)$class

```

* By following the same steps as the decision tree model, find the correct predictions.

```{r  message=FALSE, eval = FALSE}

#  Generate a column named PredictionLDA in dataframe results and add predictions obtained by LDA to that column
results$PredictionLDA <- predict(LDAmodel, newdata = results)$class

# Find the correct predictions
correct_LDA <- which(results$PredictionLDA == results$CLASS)

# Return the total number of correct predictions
length(correct_LDA)

```







**Support Vector Machine (SVM)**

The function `svm()` in package `e1071` is used to develop a SVM model. The basic syntax of this function can be given as follows

    svm(formula, data, kernel method, scale=TRUE )
    
- Formula shows which features are used in modelling to predict the target variable.

- Data is the dataset that will be used for model building.

- If our data is linearly separable, we use linear separation `kernel = "linear"`. However, if our data is not linearly separable, then we should use other separation techniques (such as `kernel = "radial"`). For other kernel techniques, you can check [R documentation](https://www.rdocumentation.org/packages/e1071/versions/1.7-2/topics/svm). 

- The last argument `scale=TRUE` is related to feature scaling. When one feature 
has very large values, it will dominate the other features when calculating the distance in SVM. Therefore, we scale them to have equal influence on the SVM metrics.

Let's load `e1071` package and start to work on the SVM model.

```{r  message=FALSE, eval = FALSE}

# Install e1071 package for SVM model
install.packages("e1071")

# Load package e1071
library(e1071)

```

***

* Build an SVM model by using all features. Set the `kernel = "radial"`. Call this model *svm_radial*.

```{r  message=FALSE, eval = FALSE}

# Build an SVM model by using svm() function
svm_radial <- svm(CLASS ~ ., data = training_set, kernel = "radial", scale = TRUE)

# Print svm_radial
print(svm_radial)

```

* Using this model, predict customer classification (1 or 0) for the test data. Use `predict()` function for this task. The basic syntax of `predict()` function for SVM takes two arguments: predictive model (in this case svm_radial) and unseen dataset which is our test set. The syntax is:

         predict(modelname, test data)

```{r  message=FALSE, eval=FALSE}

# Predicting the Test set results 
 svm_predict <- predict(svm_radial, newdata = test)

```


Let's find out how many of the predictions are correct. 

 * Copy test data to *results*  
 * Generate a column in *results* as "PredictionSVM" and add predictions obtained by SVM.
 
```{r  message=FALSE, eval=FALSE}

# Copy test data to results
results <- test

# The following code generates a column named PredictionSVM in dataframe results and adds predictions obtained by SVM to that column
results$PredictionSVM <- predict(svm_radial, newdata = results)

```
 
 * Find the correct predictions by comparing "CLASS" and "PredictionSVM" columns.

```{r  message=FALSE, eval = FALSE}

# Find the correct predictions
correct_svm <- which(results$PredictionSVM == results$CLASS)

# Return the total number of correct predictions by using length() function
length(correct_svm)

```






